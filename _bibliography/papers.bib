---
---

@string{aps = {American Physical Society,}}

@book{einstein1956investigations,
  bibtex_show={true},
  title={Investigations on the Theory of the Brownian Movement},
  author={Einstein, Albert},
  year={1956},
  publisher={Courier Corporation,},
  preview={brownian-motion.gif}
}

@article{einstein1950meaning,
  abbr={AJP},
  bibtex_show={true},
  title={The meaning of relativity},
  author={Einstein, Albert and Taub, AH},
  journal={American Journal of Physics,},
  volume={18},
  number={6},
  pages={403--404},
  year={1950},
  publisher={American Association of Physics Teachers,}
}

@article{PhysRev.47.777,
  abbr={PhysRev},
  title={Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?},
  author={Einstein, A. and Podolsky, B. and Rosen, N.},
  abstract={In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.},
  journal={Phys. Rev.,},
  volume={47},
  issue={10},
  pages={777--780},
  numpages={0},
  year={1935},
  month={May},
  publisher=aps,
  doi={10.1103/PhysRev.47.777},
  url={http://link.aps.org/doi/10.1103/PhysRev.47.777},
  html={https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777},
  pdf={example_pdf.pdf}
}

@article{einstein1905molekularkinetischen,
  title={{\"U}ber die von der molekularkinetischen Theorie der W{\"a}rme geforderte Bewegung von in ruhenden Fl{\"u}ssigkeiten suspendierten Teilchen},
  author={Einstein, A.},
  journal={Annalen der physik,},
  volume={322},
  number={8},
  pages={549--560},
  year={1905},
  publisher={Wiley Online Library}
}

@article{einstein1905movement,
  abbr={Ann. Phys.},
  title={Un the movement of small particles suspended in statiunary liquids required by the molecular-kinetic theory 0f heat},
  author={Einstein, A.},
  journal={Ann. Phys.,},
  volume={17},
  pages={549--560},
  year={1905}
}

@article{einstein1905electrodynamics,
  title={On the electrodynamics of moving bodies},
  author={Einstein, A.},
  year={1905}
}

@book{przibram1967letters,
  bibtex_show={true},
  title={Letters on wave mechanics},
  author={Einstein, Albert and Schr√∂dinger, Erwin and Planck, Max and Lorentz, Hendrik Antoon and Przibram, Karl},
  year={1967},
  publisher={Vision},
  preview={wave-mechanics.gif}
}

@phdthesis{Leterme2023b,
  abbr={Doctoral Thesis},
  type = {Doctoral Thesis},
  title = {A {{Complex Wavelet Approach}} for {{Shift-Invariant Convolutional Neural Networks}}},
  author = {Leterme, Hubert},
  year = {2023},
  month = jun,
  abstract = {Despite significant advancements in computer vision over the past decade, convolutional neural networks (CNNs) still suffer from a lack of mathematical understanding. In particular, stability properties with respect to small transformations such as translations, rotations, scaling or deformations are only partially understood. While there is a broad literature on this topic, some gaps remain, specifically with regard to the combined effect of convolution and max pooling layers in producing near shift-invariant feature representations. This property is of utmost importance for classification, since two shifted versions of a single input image are expected to receive the same label. It is well-known that subsampled convolutions with band-pass filters are prone to producing unstable image representations when inputs are shifted by a few pixels. The first contribution of this thesis consists in proving that a nonlinear max pooling operator can partially restore shift invariance. By applying results from the wavelet theory, and adopting a probabilistic point of view, we reveal a similarity between the max pooling of real-valued convolutions, as implemented in conventional architectures, and the modulus of complex-valued convolutions, for which a measure of shift invariance is established. However, for specific filter frequencies, this similarity is lost, and CNNs become unstable to translations. This phenomenon, known as aliasing, can be avoided by employing additional low-pass filters in strategic locations of the network architecture, as several authors have done in recent years. While their methods effectively increase both shift invariance and prediction accuracy, they come at the cost of significant loss of high-frequency information. As a second contribution, we present a novel antialiasing method which, unlike previous methods, preserves this information. Relying on our theoretical study, the key idea is to exploit the properties of complex convolutions to guarantee near-shift invariance for any filter frequency. By adding an imaginary part to high-frequency kernels and replacing the max pooling layer with a simple modulus operator, we empirically evidence an increase in the network's stability and a lower error rate compared to previous approaches based on low-pass filtering. In conclusion, the aim of this thesis is twofold: improving the mathematical understanding of CNNs from the perspective of shift invariance, and improving the tradeoff between stability and information preserving, based on our theoretical contribution which is grounded in wavelet theory. Our findings thus have the potential to positively impact various applications of computer vision, especially in fields that require theoretical guarantees.},
  langid = {english},
  school = {Universit\'e Grenoble Alpes},
  pdf = {Leterme_2023_A Complex Wavelet Approach for Shift-Invariant Convolutional Neural Networks.pdf},
  selected = {true}
}

@article{Leterme2023a,
  abbr={Preprint},
  title = {From {{CNNs}} to {{Shift-Invariant Twin Models Based}} on {{Complex Wavelets}}},
  author = {Leterme, Hubert and Polisano, K{\'e}vin and Perrier, Val{\'e}rie and Alahari, Karteek},
  year = {2023},
  month = mar,
  njournal = {arXiv:2212.00394},
  eprint = {2212.00394},
  primaryclass = {cs, eess, stat},
  doi = {10.48550/arXiv.2212.00394},
  abstract = {We propose a novel antialiasing method to increase shift invariance in convolutional neural networks (CNNs). More precisely, we replace the conventional combination "real-valued convolutions + max pooling" (\$\textbackslash mathbb R\$Max) by "complex-valued convolutions + modulus" (\$\textbackslash mathbb C\$Mod), which produce stable feature representations for band-pass filters with well-defined orientations. In a recent work, we proved that, for such filters, the two operators yield similar outputs. Therefore, \$\textbackslash mathbb C\$Mod can be viewed as a stable alternative to \$\textbackslash mathbb R\$Max. To separate band-pass filters from other freely-trained kernels, in this paper, we designed a "twin" architecture based on the dual-tree complex wavelet packet transform, which generates similar outputs as standard CNNs with fewer trainable parameters. In addition to improving stability to small shifts, our experiments on AlexNet and ResNet showed increased prediction accuracy on natural image datasets such as ImageNet and CIFAR10. Furthermore, our approach outperformed recent antialiasing methods based on low-pass filtering by preserving high-frequency information, while reducing memory usage.},
  archiveprefix = {arxiv},
  file = {/home/letermeh/OneDrive/boox/zotero/Leterme et al_2023_From CNNs to Shift-Invariant Twin Models Based on Complex Wavelets3.pdf;/home/letermeh/Zotero/storage/MTNKFSYZ/2212.html},
  html = {https://arxiv.org/abs/2212.00394},
  pdf = {Leterme et al_2023_From CNNs to Shift-Invariant Twin Models Based on Complex Wavelets.pdf},
  selected = {true}
}

@article{Leterme2022,
  abbr={Preprint},
  title = {On the {{Shift Invariance}} of {{Max Pooling Feature Maps}} in {{Convolutional Neural Networks}}},
  author = {Leterme, Hubert and Polisano, K{\'e}vin and Perrier, Val{\'e}rie and Alahari, Karteek},
  year = {2022},
  month = sep,
  njournal = {arXiv:2209.11740},
  eprint = {2209.11740},
  eprinttype = {arxiv},
  doi = {10.48550/arXiv.2209.11740},
  abstract = {In this paper, we aim to improve the mathematical interpretability of convolutional neural networks for image classification. When trained on natural image datasets, such networks tend to learn parameters in the first layer that closely resemble oriented Gabor filters. By leveraging the properties of discrete Gabor-like convolutions, we prove that, under specific conditions, feature maps computed by the subsequent max pooling operator tend to approximate the modulus of complex Gabor-like coefficients, and as such, are stable with respect to certain input shifts. We then compute a probabilistic measure of shift invariance for these layers. More precisely, we show that some filters, depending on their frequency and orientation, are more likely than others to produce stable image representations. We experimentally validate our theory by considering a deterministic feature extractor based on the dual-tree wavelet packet transform, a particular case of discrete Gabor-like decomposition. We demonstrate a strong correlation between shift invariance on the one hand and similarity with complex modulus on the other hand.},
  archiveprefix = {arXiv},
  file = {/home/letermeh/Cloud_UGA/Documents/Zotero/storage/ZZZTKCLL/Leterme et al_2022_On the Shift Invariance of Max Pooling Feature Maps in Convolutional Neural.pdf;/home/letermeh/Cloud_UGA/Documents/Zotero/storage/T54B3VZI/2209.html},
  html = {https://arxiv.org/abs/2209.11740},
  pdf = {Leterme et al_2022_On the Shift Invariance of Max Pooling Feature Maps in Convolutional Neural.pdf},
  selected = {true}
}

@inproceedings{Leterme2021,
  abbr={Workshop},
  title = {Mod\'elisation {{Parcimonieuse}} de {{CNNs}} Avec Des {{Paquets}} d'{{Ondelettes Dual-Tree}}},
  booktitle = {{{ORASIS,}}},
  author = {Leterme, Hubert and Polisano, K{\'e}vin and Perrier, Val{\'e}rie and Alahari, Karteek},
  year = {2021},
  month = sep,
  publisher = {{Centre National de la Recherche Scientifique [CNRS]}},
  address = {{Saint Ferr\'eol, France}},
  language = {french},
  abstract = {We propose to improve the mathematical interpretability of convolutional neural networks (CNNs) for image classification. In this purpose, we replace the first layers of existing models such as AlexNet or ResNet by an operator containing the dual-tree wavelet packet transform, i.e., a redundant decomposition using complex and oriented waveforms. Our experiments show that these modified networks behave very similarly to the original models once trained. The goal is then to study this operator from a theoretical point of view and to identify potential optimizations. We want to analyze its main properties such as directional selectivity, stability with respect to small shifts and rotations, thus retaining discriminant information while decreasing intra-class variability. This work is a step toward a more complete description of CNNs using well-defined mathematical operators, characterized by a small number of arbitrary parameters, making them easier to interpret.},
  file = {/home/letermeh/Cloud_UGA/Documents/Zotero/storage/8LHDPVC6/Leterme et al_2021_Mod√©lisation Parcimonieuse de CNNs avec des Paquets d'Ondelettes Dual-Tree.pdf},
  html = {https://hal.archives-ouvertes.fr/hal-03339792/},
  pdf = {orasis2021_article_v2bis.pdf},
  selected = {false}
}
